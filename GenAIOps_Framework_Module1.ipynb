{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxtAsDYd4ont52nQZgp9a1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashmisingh100-dev/Project-X/blob/main/GenAIOps_Framework_Module1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFavuHwW2qXp",
        "outputId": "6a2f4908-226e-444c-fea2-d655cdf074e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenAIOps Framework - Starting Setup\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "#GenAI Ops Framework - Module 1: Foundation\n",
        "#This module builds the core GenAI components\n",
        "print(\"GenAIOps Framework - Starting Setup\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Visual Directory Setup\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "Aaugcm203HlT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup directories\n",
        "base_dir= Path('/content/genaiops')\n",
        "base_dir.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "XyDJvnhe3Csp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create subsidirectories\n",
        "(base_dir/'prompts').mkdir(exist_ok=True)\n",
        "(base_dir / 'models').mkdir(exist_ok=True)\n",
        "(base_dir / 'evaluations').mkdir(exist_ok=True)\n",
        "(base_dir / 'logs').mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "_-ISBxDc36Nj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"‚úÖ Environment ready!\")\n",
        "print(f\"üìÅ Base directory: {base_dir}\")\n",
        "print()\n",
        "print(\"üëâ You can now run the rest of the notebook\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_7XCAwW3jLH",
        "outputId": "246362af-b6a4-41bb-c4cc-55829e456cb0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Environment ready!\n",
            "üìÅ Base directory: /content/genaiops\n",
            "\n",
            "üëâ You can now run the rest of the notebook\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#verify setup worked\n",
        "import os\n",
        "print(\"üîç Verifying GenAIOps directory structure...\")\n",
        "print()\n",
        "\n",
        "for folder in ['prompts', 'models', 'evaluations', 'logs']:\n",
        "    path = f'/content/genaiops/{folder}'\n",
        "    exists = os.path.exists(path)\n",
        "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
        "    print(f\"{status} {path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3ZmVuNXAXc-",
        "outputId": "e950b84e-b9dc-412e-ca23-d9a8da413b52"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Verifying GenAIOps directory structure...\n",
            "\n",
            "‚úÖ /content/genaiops/prompts\n",
            "‚úÖ /content/genaiops/models\n",
            "‚úÖ /content/genaiops/evaluations\n",
            "‚úÖ /content/genaiops/logs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# COMPONENT 1: Prompt Management System\n",
        "# ========================================\n",
        "print(\"üìù Building Prompt Management System...\")\n",
        "print()\n",
        "#Define Prompt Template for Customer Support\n",
        "customer_support_prompt_v1 = \"\"\"\n",
        "You are a helpful customer service representative for Prudential Financial.\n",
        "\n",
        "Customer Question:{customer_question}\n",
        "\n",
        "Instructions:\n",
        "- Be professional and empathetic\n",
        "- Provide accurate information about policies, only factual and grounded answer with no hallucination\n",
        "- If you don't know the answer, say so clearly\n",
        "- Keep response under 150 words\n",
        "- Include next steps when applicable\n",
        "- Professional yet conversational tone\n",
        "- Include 2-3 specific next steps\n",
        "- Offer specialist escalation if complex\n",
        "\n",
        "Safety Rules:\n",
        "- Never provide medical advice\n",
        "- Never make financial predictions\n",
        "- Don't discuss other customers\n",
        "- Escalate legal questions to compliance team\n",
        "Response:\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpfeMYoEAvBE",
        "outputId": "430a43ec-d0f0-4b87-b3b4-2d86f7d0c2fa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Building Prompt Management System...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save this prompt to our prompts directory\n",
        "prompt_file_path = '/content/genaiops/prompts/customer_support_v1.0.txt'\n",
        "\n",
        "with open(prompt_file_path, 'w') as f:\n",
        "    f.write(customer_support_prompt_v1)\n",
        "\n",
        "print(f\"‚úÖ Prompt saved to: {prompt_file_path}\")\n",
        "print()\n",
        "print(\"üìÑ Prompt content:\")\n",
        "print(\"-\" * 50)\n",
        "print(customer_support_prompt_v1)\n"
      ],
      "metadata": {
        "id": "9cf-fKg8FgHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067229ef-8387-4b12-def2-53c4b8106785"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prompt saved to: /content/genaiops/prompts/customer_support_v1.0.txt\n",
            "\n",
            "üìÑ Prompt content:\n",
            "--------------------------------------------------\n",
            "\n",
            "You are a helpful customer service representative for Prudential Financial.\n",
            "\n",
            "Customer Question:{customer_question}\n",
            "\n",
            "Instructions:\n",
            "- Be professional and empathetic\n",
            "- Provide accurate information about policies, only factual and grounded answer with no hallucination\n",
            "- If you don't know the answer, say so clearly\n",
            "- Keep response under 150 words\n",
            "- Include next steps when applicable\n",
            "- Professional yet conversational tone\n",
            "- Include 2-3 specific next steps\n",
            "- Offer specialist escalation if complex\n",
            "\n",
            "Safety Rules:\n",
            "- Never provide medical advice\n",
            "- Never make financial predictions\n",
            "- Don't discuss other customers\n",
            "- Escalate legal questions to compliance team\n",
            "Response:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prompt Metadata (Governance)\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Create metadata for our prompt\n",
        "prompt_metadata = {\n",
        "    \"prompt_id\": \"customer_support_v1.0\",\n",
        "    \"version\": \"1.0\",\n",
        "    \"created_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "    \"created_by\": \"Rashmi Singh\",\n",
        "    \"status\": \"approved\",\n",
        "    \"use_case\": \"Customer service chatbot\",\n",
        "    \"model_compatibility\": [\"gemini-1.5-pro\", \"gemini-1.5-flash\"],\n",
        "    \"approved_by\": \"Data & AI COE (Group)\",\n",
        "    \"approval_date\": \"2024-02-14\",\n",
        "    \"description\": \"Professional customer service prompt with empathy and accuracy focus\",\n",
        "    \"test_pass_rate\": 0.95,  # 95% of test cases passed\n",
        "    \"production_apps\": [\"CustomerSupportBot\", \"EmailAutomation\"]\n",
        "}\n",
        "\n",
        "# Save metadata as JSON\n",
        "metadata_file = '/content/genaiops/prompts/customer_support_v1.0_metadata.json'\n",
        "\n",
        "with open(metadata_file, 'w') as f:\n",
        "    json.dump(prompt_metadata, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Prompt metadata saved\")\n",
        "print()\n",
        "print(\"üìã Metadata:\")\n",
        "print(json.dumps(prompt_metadata, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FLL4wkWmlYK",
        "outputId": "3e9c3622-77ff-4971-f741-ec152e3fbeda"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Prompt metadata saved\n",
            "\n",
            "üìã Metadata:\n",
            "{\n",
            "  \"prompt_id\": \"customer_support_v1.0\",\n",
            "  \"version\": \"1.0\",\n",
            "  \"created_date\": \"2026-02-14\",\n",
            "  \"created_by\": \"Rashmi Singh\",\n",
            "  \"status\": \"approved\",\n",
            "  \"use_case\": \"Customer service chatbot\",\n",
            "  \"model_compatibility\": [\n",
            "    \"gemini-1.5-pro\",\n",
            "    \"gemini-1.5-flash\"\n",
            "  ],\n",
            "  \"approved_by\": \"Data & AI COE (Group)\",\n",
            "  \"approval_date\": \"2024-02-14\",\n",
            "  \"description\": \"Professional customer service prompt with empathy and accuracy focus\",\n",
            "  \"test_pass_rate\": 0.95,\n",
            "  \"production_apps\": [\n",
            "    \"CustomerSupportBot\",\n",
            "    \"EmailAutomation\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prompt Loader Function\n",
        "\n",
        "def load_prompt(prompt_id, version=\"latest\"):\n",
        "    \"\"\"\n",
        "    Load a prompt template by ID and version\n",
        "\n",
        "    Args:\n",
        "        prompt_id: Name of the prompt (e.g., 'customer_support')\n",
        "        version: Version number (e.g., '1.0') or 'latest'\n",
        "\n",
        "    Returns:\n",
        "        dict with 'template' and 'metadata'\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct file paths\n",
        "    if version == \"latest\":\n",
        "        # In real system, would query database for latest version\n",
        "        # For now, we'll use v1.0\n",
        "        version = \"1.0\"\n",
        "\n",
        "    prompt_file = f'/content/genaiops/prompts/{prompt_id}_v{version}.txt'\n",
        "    metadata_file = f'/content/genaiops/prompts/{prompt_id}_v{version}_metadata.json'\n",
        "\n",
        "    # Load prompt template\n",
        "    try:\n",
        "        with open(prompt_file, 'r') as f:\n",
        "            template = f.read()\n",
        "    except FileNotFoundError:\n",
        "        return {\"error\": f\"Prompt {prompt_id} v{version} not found\"}\n",
        "\n",
        "    # Load metadata\n",
        "    try:\n",
        "        with open(metadata_file, 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        metadata = {\"warning\": \"No metadata found\"}\n",
        "\n",
        "    return {\n",
        "        \"template\": template,\n",
        "        \"metadata\": metadata\n",
        "    }\n",
        "\n",
        "\n",
        "# Test the loader\n",
        "print(\"üß™ Testing prompt loader...\")\n",
        "print()\n",
        "\n",
        "result = load_prompt(\"customer_support\", version=\"1.0\")\n",
        "\n",
        "print(\"‚úÖ Prompt loaded successfully!\")\n",
        "print()\n",
        "print(\"üìÑ Template:\")\n",
        "print(result['template'][:200] + \"...\")  # First 200 chars\n",
        "print()\n",
        "print(\"üìã Metadata:\")\n",
        "print(f\"  Version: {result['metadata']['version']}\")\n",
        "print(f\"  Status: {result['metadata']['status']}\")\n",
        "print(f\"  Use Case: {result['metadata']['use_case']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w5KD_4xq2Wf",
        "outputId": "f562dcb2-5998-47c1-e848-c681b4846aa9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ Testing prompt loader...\n",
            "\n",
            "‚úÖ Prompt loaded successfully!\n",
            "\n",
            "üìÑ Template:\n",
            "\n",
            "You are a helpful customer service representative for Prudential Financial.\n",
            "\n",
            "Customer Question:{customer_question}\n",
            "\n",
            "Instructions:\n",
            "- Be professional and empathetic\n",
            "- Provide accurate information about...\n",
            "\n",
            "üìã Metadata:\n",
            "  Version: 1.0\n",
            "  Status: approved\n",
            "  Use Case: Customer service chatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prompt Version Comparison Tool\n",
        "# Create an improved version (v1.1)\n",
        "customer_support_prompt_v1_1 = \"\"\"\n",
        "You are an empathetic customer service representative for Prudential Financial with deep knowledge of our insurance products and policies.\n",
        "\n",
        "Customer Profile:\n",
        "- Name: {customer_name}\n",
        "- Policy Type: {policy_type}\n",
        "- Customer Since: {customer_since}\n",
        "\n",
        "Customer Question:\n",
        "{customer_question}\n",
        "\n",
        "Instructions:\n",
        "- Address customer by name to personalize the response\n",
        "- Be professional, empathetic, and solution-oriented\n",
        "- Reference their specific policy type when relevant\n",
        "- Provide accurate information about Prudential policies\n",
        "- If you don't know the answer, be honest and offer to connect them with a specialist\n",
        "- Keep response under 150 words\n",
        "- Always include clear next steps\n",
        "- End with \"Is there anything else I can help you with today?\"\n",
        "- Professional yet conversational tone\n",
        "- Include 2-3 specific next steps\n",
        "- Offer specialist escalation if complex\n",
        "\n",
        "Safety Rules:\n",
        "- Never provide medical advice\n",
        "- Never make financial predictions\n",
        "- Don't discuss other customers\n",
        "- Escalate legal questions to compliance team\n",
        "\n",
        "Response:\n",
        "\"\"\"\n",
        "\n",
        "# Save v1.1\n",
        "prompt_v1_1_path = '/content/genaiops/prompts/customer_support_v1.1.txt'\n",
        "with open(prompt_v1_1_path, 'w') as f:\n",
        "    f.write(customer_support_prompt_v1_1)\n",
        "\n",
        "# Create metadata for v1.1\n",
        "metadata_v1_1 = {\n",
        "    \"prompt_id\": \"customer_support_v1.1\",\n",
        "    \"version\": \"1.1\",\n",
        "    \"created_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "    \"created_by\": \"Rashmi Singh\",\n",
        "    \"status\": \"testing\",  # Not yet approved for production\n",
        "    \"use_case\": \"Customer service chatbot\",\n",
        "    \"model_compatibility\": [\"gemini-1.5-pro\", \"gemini-1.5-flash\"],\n",
        "    \"description\": \"Enhanced with personalization and policy-type awareness\",\n",
        "    \"improvements_over_v1.0\": [\n",
        "        \"Personalization with customer name\",\n",
        "        \"Policy-type specific responses\",\n",
        "        \"Customer tenure awareness\",\n",
        "        \"Standardized closing question\"\n",
        "    ],\n",
        "    \"test_pass_rate\": None,  # Not yet tested\n",
        "    \"production_apps\": []  # Not yet deployed\n",
        "}\n",
        "\n",
        "metadata_v1_1_path = '/content/genaiops/prompts/customer_support_v1.1_metadata.json'\n",
        "with open(metadata_v1_1_path, 'w') as f:\n",
        "    json.dump(metadata_v1_1, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Created prompt v1.1 (improved version)\")\n",
        "print()\n",
        "print(\"üÜö Comparing v1.0 vs v1.1:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"v1.0 (Production):\")\n",
        "print(\"  - Generic customer addressing\")\n",
        "print(\"  - No personalization\")\n",
        "print(\"  - Status: Approved ‚úÖ\")\n",
        "print()\n",
        "print(\"v1.1 (Testing):\")\n",
        "print(\"  - Personalized with customer name\")\n",
        "print(\"  - Policy-type aware\")\n",
        "print(\"  - Customer tenure aware\")\n",
        "print(\"  - Standardized closing\")\n",
        "print(\"  - Status: Testing üß™\")\n",
        "print()\n",
        "print(\"üìä Next step: A/B testing to compare quality\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NWdsm_grCZO",
        "outputId": "87f1ff4a-38b1-4ca8-92bd-ed21e6d6b259"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Created prompt v1.1 (improved version)\n",
            "\n",
            "üÜö Comparing v1.0 vs v1.1:\n",
            "------------------------------------------------------------\n",
            "v1.0 (Production):\n",
            "  - Generic customer addressing\n",
            "  - No personalization\n",
            "  - Status: Approved ‚úÖ\n",
            "\n",
            "v1.1 (Testing):\n",
            "  - Personalized with customer name\n",
            "  - Policy-type aware\n",
            "  - Customer tenure aware\n",
            "  - Standardized closing\n",
            "  - Status: Testing üß™\n",
            "\n",
            "üìä Next step: A/B testing to compare quality\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMPTtkbcxRIy"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}